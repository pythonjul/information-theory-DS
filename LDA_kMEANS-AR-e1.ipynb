{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import sklearn.datasets, sklearn.decomposition, sklearn.discriminant_analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def traintestMNIST(labels=None, ntrain=None, ntest=None, path=os.path.join('data_for_python', 'mnist.npz')):\n",
    "    mnist = np.load(path)\n",
    "    train_x = mnist['train_x']\n",
    "    train_y = mnist['train_y']\n",
    "    train = np.asarray(list(zip(train_x, train_y)))\n",
    "\n",
    "    test_x = mnist['test_x']\n",
    "    test_y = mnist['test_y']\n",
    "    test = np.asarray(list(zip(test_x, test_y)))\n",
    "\n",
    "    if labels:\n",
    "        train = list(train[np.hstack([np.where(train_y==l) for l in labels]).squeeze()])\n",
    "        test = list(test[np.hstack([np.where(test_y==l) for l in labels]).squeeze()])\n",
    "\n",
    "    random.shuffle(train)\n",
    "    random.shuffle(test)\n",
    "\n",
    "    train_x, train_y = zip(*train)\n",
    "    test_x, test_y = zip(*test)\n",
    "\n",
    "    if ntrain:\n",
    "        train_x = train_x[:ntrain]\n",
    "        train_y = train_y[:ntrain]\n",
    "\n",
    "    if ntest:\n",
    "        test_x = test_x[:ntest]\n",
    "        test_y = test_y[:ntest]\n",
    "\n",
    "    return np.asarray(train_x), np.asarray(train_y), np.asarray(test_x), np.asarray(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(_):\n",
    "    #on calcule séparemment pour avoir le meme nombre de 3 et de 7, qui est une hypothèse pour que notre méthode fonctionne.\n",
    "    [trainImages3, trainLabels3, testImages3, testLabels3] = traintestMNIST([3],2000 )\n",
    "    [trainImages7, trainLabels7, testImages7, testLabels7] = traintestMNIST([7],2000 )\n",
    "\n",
    "    #on assemble les données concernant les 3 et les 7.\n",
    "    trainImages=np.concatenate((trainImages3,trainImages7))\n",
    "    trainLabels=np.concatenate((trainLabels3,trainLabels7))\n",
    "    testImages=np.concatenate((testImages3,testImages7))\n",
    "    testLabels=np.concatenate((testLabels3,testLabels7))\n",
    "    \n",
    "    #on prend uniquement les 50 premiers vect propres.\n",
    "    pca = sklearn.decomposition.PCA(50)\n",
    "    train_img_fit=pca.fit_transform(trainImages)\n",
    "    test_img_fit=pca.fit_transform(testImages)\n",
    "    \n",
    "    #LDA\n",
    "    mon_LDA=sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "    mon_LDA.fit(train_img_fit,trainLabels)\n",
    "    LDA_estimated = mon_LDA.predict(test_img_fit)\n",
    "    conf_mat_LDA=confusion_matrix(testLabels,LDA_estimated)\n",
    "    #confusion_matrix de sklearn tq (truth , estimated)\n",
    "\n",
    "    #1-NN\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(train_img_fit, trainLabels)\n",
    "    NN_estimated=neigh.predict(test_img_fit)\n",
    "    conf_mat_1NN=confusion_matrix(testLabels,NN_estimated)\n",
    "    return (conf_mat_LDA,conf_mat_1NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[]\n",
    "for i in range(50):\n",
    "    c.append(f(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour matrice de confusion:\n",
      "\n",
      "  LDA\n",
      "\n",
      "  1-NN\n",
      "---------\n",
      "mean:\n",
      "\n",
      "[[[949.24  60.76]\n",
      "  [ 35.74 992.26]]\n",
      "\n",
      " [[958.28  51.72]\n",
      "  [ 34.36 993.64]]]\n",
      "---------\n",
      "median:\n",
      "\n",
      "[[[ 949.    61. ]\n",
      "  [  35.5  992.5]]\n",
      "\n",
      " [[ 972.5   37.5]\n",
      "  [  25.5 1002.5]]]\n",
      "---------\n",
      "min:\n",
      "\n",
      "[[[914  39]\n",
      "  [ 13 974]]\n",
      "\n",
      " [[882  29]\n",
      "  [ 10 932]]]\n",
      "---------\n",
      "max:\n",
      "\n",
      "[[[ 971   96]\n",
      "  [  54 1015]]\n",
      "\n",
      " [[ 981  128]\n",
      "  [  96 1018]]]\n"
     ]
    }
   ],
   "source": [
    "print('Pour matrice de confusion:\\n\\n  LDA\\n\\n  1-NN')\n",
    "print('---------\\nmean:\\n')\n",
    "print(np.mean(c,0))\n",
    "print('---------\\nmedian:\\n')\n",
    "print(np.median(c,0))\n",
    "print('---------\\nmin:\\n')\n",
    "print(np.amin(c,0))\n",
    "print('---------\\nmax:\\n')\n",
    "print(np.amax(c,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[950  60]\n",
      " [ 61 967]]\n",
      "[[872 138]\n",
      " [ 82 946]]\n"
     ]
    }
   ],
   "source": [
    "a=f(1)\n",
    "print(a[0])\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
